{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, t\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 500\n",
    "from statistics import stdev, mean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t- distribution Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_ci(confidence_interval: float = 0.90,\n",
    "            sample_std_dev: float = 1,\n",
    "            number_of_samples:int = 2,\n",
    "            mean: float = 0,\n",
    "            two_sided: bool = True\n",
    "            ):\n",
    "    '''\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    confidence_interval : float, optional\n",
    "        DESCRIPTION. The default is 0.90.\n",
    "    sample_std_dev : float, optional\n",
    "        DESCRIPTION. The default is 1.\n",
    "    number_of_samples : int, optional\n",
    "        DESCRIPTION. The default is 100.\n",
    "    mean : float, optional\n",
    "        DESCRIPTION. The default is 0.\n",
    "    two_sided : bool, optional\n",
    "        DESCRIPTION. The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TYPE\n",
    "        DESCRIPTION.\n",
    "\n",
    "    '''\n",
    "    # declaring problem constants\n",
    "    x_bar = mean\n",
    "    n = number_of_samples # number of samples taken\n",
    "    sigma = sample_std_dev # population standard deviation\n",
    "    sigma_x_bar = sigma/n**0.5 # std dev of sample means\n",
    "    df = n-1 # degrees of freedom\n",
    "    \n",
    "    # generate x within 3.5 standard deviations and y axes\n",
    "    x_axis_lower_bound = x_bar-3.5*sigma_x_bar\n",
    "    x_axis_upper_bound = x_bar+3.5*sigma_x_bar\n",
    "    steps = (x_axis_upper_bound-x_axis_lower_bound)/1000\n",
    "    x = np.arange(x_axis_lower_bound,x_axis_upper_bound,steps)\n",
    "    y = t.pdf(x,df, loc=x_bar,scale=sigma_x_bar)\n",
    "    \n",
    "    # get the probabilities of the tail areas\n",
    "    if two_sided:\n",
    "        alpha_high = (1+confidence_interval)/2\n",
    "        alpha_low = (1-confidence_interval)/2\n",
    "    else:\n",
    "        alpha_high = confidence_interval\n",
    "        alpha_low = 0\n",
    "    # compute the value of x_lower and x_higher\n",
    "    x_lower = t.ppf(alpha_low,df,loc=x_bar,scale=sigma_x_bar)\n",
    "    x_higher = t.ppf(alpha_high,df,loc=x_bar,scale=sigma_x_bar)\n",
    "    return round(x_lower,3), round(x_higher,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'SA1_Group_17.csv', index_col='Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the numerical and non-numerical columns\n",
    "A separate dataset has been prepared to list out the numerical and the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_desc = pd.read_csv(r'Data description.csv')\n",
    "categorical_cols = column_desc.non_numeric_columns.dropna().tolist()\n",
    "numeric_cols = column_desc.numeric_columns.dropna().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the dataset descriptive statistics of the numerical columns\n",
    "Some Important points\n",
    " - Though OPER_DUR_DD is expected to be a continuous variable it looks like the rows are missing various data eventhough unit was operational. It just don't make sense that OPER_DUR_MM is filled (meaning the unit was operational for given number of months) but don't have the data OPER_DUR_DD (duration of operation in days). So for the descriptive statistics we will omit this as of now.\n",
    " - Other columns which are dropped because they are categorical in nature but were encoded. Getting descriptive statistics for categorical columns doesn't make sense. We will get distinct counts of them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for the numerical columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPER_DUR_MM</th>\n",
       "      <th>MKT_VAL_FA</th>\n",
       "      <th>ORI_PURC_VAL_PM</th>\n",
       "      <th>EMP_TOTAL</th>\n",
       "      <th>GOP_Year3</th>\n",
       "      <th>VOE_Year3</th>\n",
       "      <th>NET_Year3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.559000</td>\n",
       "      <td>8.547566e+05</td>\n",
       "      <td>3.245659e+05</td>\n",
       "      <td>5.885900</td>\n",
       "      <td>9.259034e+07</td>\n",
       "      <td>2.855352e+04</td>\n",
       "      <td>1.200584e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.111437</td>\n",
       "      <td>5.466470e+06</td>\n",
       "      <td>1.791879e+06</td>\n",
       "      <td>10.858502</td>\n",
       "      <td>9.081048e+09</td>\n",
       "      <td>1.225493e+06</td>\n",
       "      <td>8.056149e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.500000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.666250e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.700000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>5.045000e+04</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.590000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>1.900000e+05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.800000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.112225e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.653958e+08</td>\n",
       "      <td>8.961474e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>9.081050e+11</td>\n",
       "      <td>9.430860e+07</td>\n",
       "      <td>4.269214e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OPER_DUR_MM    MKT_VAL_FA  ORI_PURC_VAL_PM     EMP_TOTAL  \\\n",
       "count  10000.000000  1.000000e+04     1.000000e+04  10000.000000   \n",
       "mean      10.559000  8.547566e+05     3.245659e+05      5.885900   \n",
       "std        2.111437  5.466470e+06     1.791879e+06     10.858502   \n",
       "min        0.000000  0.000000e+00     0.000000e+00      1.000000   \n",
       "25%       10.000000  5.000000e+04     2.000000e+04      2.000000   \n",
       "50%       12.000000  1.500000e+05     5.045000e+04      3.000000   \n",
       "75%       12.000000  5.000000e+05     1.900000e+05      6.000000   \n",
       "max       12.000000  3.653958e+08     8.961474e+07    350.000000   \n",
       "\n",
       "          GOP_Year3     VOE_Year3     NET_Year3  \n",
       "count  1.000000e+04  1.000000e+04  1.000000e+04  \n",
       "mean   9.259034e+07  2.855352e+04  1.200584e+06  \n",
       "std    9.081048e+09  1.225493e+06  8.056149e+06  \n",
       "min    0.000000e+00  0.000000e+00 -3.500000e+06  \n",
       "25%    4.666250e+04  0.000000e+00  5.700000e+04  \n",
       "50%    1.000000e+05  0.000000e+00  1.590000e+05  \n",
       "75%    3.800000e+05  0.000000e+00  5.112225e+05  \n",
       "max    9.081050e+11  9.430860e+07  4.269214e+08  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Descriptive Statistics for the numerical columns')\n",
    "display(df[numeric_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference:</b>Two majorly important columns GOP_Year3 and VOE_Year3 contains outliers. This is evident from their difference between mean and median. Let's try to remove the data which is the outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick view about the two columns containing outliers\n",
    "Below we plot a scatter plot to visualize the presence of outliers in both the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28807d6a148>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAESCAYAAAAYMKWkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAV/0lEQVR4nO3de5BcZZ3G8efpzDAZEtAxGdci4xIB5aKGgIOiUbYE1hsYtAK14KW8UBuxEBGwEm/lZb2URBAtF10DXsoVUWEowcuybsmqqAhMMBmI8c5tAhZDTCTDTiYT+rd/9AnpSWbSPUmfOd3vfD9VU+l+z+nz/qZr5sk77zn9HkeEAABpKhVdAAAgP4Q8ACSMkAeAhBHyAJAwQh4AEkbIA0DCmjLkbX/V9iO276lj3ytsr82+/mB7y3TUCACtwM14nbztkyQNS/pGRDxvCq+7QNJxEfH23IoDgBbSlCP5iPi5pL9Vt9k+3PbNttfYvtX2URO89BxJ105LkQDQAtqKLmAKVks6LyL+aPtFkr4o6eSdG20fKulZkm4pqD4AaDotEfK250p6iaTrbO9s7thtt7MlXR8RT0xnbQDQzFoi5FWZVtoSEYv3ss/Zks6fpnoAoCU05Zz87iLiMUn32j5Lklxx7M7tto+U1CXptoJKBICm1JQhb/taVQL7SNuDts+V9EZJ59peJ2m9pDOqXnKOpG9HM14qBAAFaspLKAEAjdGUI3kAQGM01YnX+fPnx8KFC4suAwBaypo1ax6NiO6JtjVVyC9cuFD9/f1FlwEALcX2/ZNtY7oGABJGyANAwgh5AEgYIQ8ACSPkASBhyYT8puFRrXtwizYNjxZdCgA0jaa6hHJf3bh2o1b2Dai9VNJYuaxVyxZp6eIFRZcFAIVr+ZH8puFRrewb0LaxsraO7tC2sbJW9A0wogcAJRDyg5tH1F4a/220l0oa3DxSUEUA0DxaPuR7ujo1Vi6Paxsrl9XT1VlQRQDQPFo+5OfN7dCqZYs0u72kgzraNLu9pFXLFmne3N1vHAUAM08SJ16XLl6gJUfM1+DmEfV0dRLwAJBJIuSlyoiecAeA8Vp+ugYAMDlCHgASRsgDQMIIeQBIGCEPAAkj5AEgYYQ8ACSMkAeAhBHyAJAwQh4AEkbIA0DCCHkASBghDwAJI+QBIGGEPAAkjJAHgIQR8gCQMEIeABJGyANAwgh5AEgYIQ8ACSPkASBhuYe87Ytsr7d9j+1rbc/Ou08AQEWuIW97gaR3S+qNiOdJmiXp7Dz7BADsMh3TNW2SOm23STpQ0kPT0CcAQDmHfERslHSZpAckPSzp7xHx4+p9bC+33W+7f2hoKM9yAGDGyXu6pkvSGZKeJekQSXNsv6l6n4hYHRG9EdHb3d2dZzkAMOPkPV1zqqR7I2IoIsYk3SDpJTn3CQDI5B3yD0g60faBti3pFEkbcu4TAJDJe07+dknXS7pL0t1Zf6vz7BMAsEtb3h1ExEckfSTvfgAAe+ITrwCQMEIeABJGyANAwgh5AEgYIQ8ACSPkASBhhDwAJIyQB4CEEfIAkDBCHgASRsgDQMIIeQBIGCEPAAkj5AEgYYQ8ACSMkAeAhBHyAJAwQh4AEkbIA0DCCHkASBghDwAJI+QBIGGEPAAkjJAHgIQR8gCQMEIeABJGyANAwgh5AEgYIQ8ACSPkASBhhDwAJIyQB4CEEfIAkLDcQ972U21fb/t3tjfYfnHefQIAKtqmoY/PS7o5Is60fYCkA6ehTwCAcg552wdLOknSWyUpIrZL2p5nnwCAXfKerjlM0pCkr9n+je2rbc+p3sH2ctv9tvuHhoZyLgcAZpa8Q75N0vGSvhQRx0l6XNL7qneIiNUR0RsRvd3d3TmXAwAzS94hPyhpMCJuz55fr0roAwCmQc2Qt12yXcoeH2D7eNtPq+fgEfFXSQ/aPjJrOkXSb/e5WgDAlOw15G2/TtLDkjbaPkPSrZIukzRg+7V19nGBpGtsD0haLOlT+1EvAGAKal1d8xFJx0rqlLRO0gkR8Xvbh0rqk/T9Wh1ExFpJvftbKABg6mpeQplNucj2AxHx+6zt/p1TOACA5lXXnHz28O1VbbMkHZBXUQCAxqgV8suVhXlE3FHV/kxJn86rKABAY+w15CPiTkljtr+5W/t9EfHNSV5WiE3Do1r34BZtGh4tuhQAaBr1zMk/Ybvb9gHZsgRN58a1G7Wyb0DtpZLGymWtWrZISxcvKLosAChcvWvX3Cfpl7ZvUuVTq5KkiPhsHkVNxabhUa3sG9C2sbK2qSxJWtE3oCVHzNe8uR0FVwcAxao35B/KvkqSDsqvnKkb3Dyi9lLpyYCXpPZSSYObRwh5ADNeXSEfER/Lu5B91dPVqbFyeVzbWLmsnq7OgioCgOZR17Xu2Zz8Z2z/yPYtO7/yLq4e8+Z2aNWyRZrdXtJBHW2a3V7SqmWLGMUDgOqfrrlG0ncknS7pPElvUWUJ4aawdPECLTlivgY3j6inq5OAB4BMvSE/LyK+YvvCiPiZpJ/Z/lmehU3VvLkdhDsA7KbekB/L/n3Y9mmqnITtyackAECj1Bvyn7D9FEmXSPqCpIMlXZRbVQCAhqj36pofZA//Lunl+ZUDAGikeq+ueY7tn9i+J3u+yPaH8i0NALC/6l0u+CpJ71c2Nx8RA5LOzquofcHaNQCwp3rn5A+MiDtsV7ftyKGefcLaNQAwsXpH8o/aPlxSSJLtM1W5LWDhqteu2Tq6Q9vGylrRN8CIHgBU+x6vK7IbhJwv6cuSjrK9UdJ7JL1zGuqraefaNdV2rl0DADNdremaQyWtkXR+RJxqe46kUkRszb+0+rB2DQBMrtZNQ85X5bZ/q2x/RdLRkp5t+3jbx09HgbWwdg0ATK6em4bcZfuDkvokPTkvn/17co611Y21awBgYnsNedtPl3S5pMMknRwR66alqn3A2jUAsKdaV9f8WtKtkl7azAEPAJhYrZB/UUSsjojY2062+xpYEwCgQWqdeK13zfjDGlALAKDB6v0wVC17HekDAIrRqJAHADShRoW8a+8CAJhutZY1OHgv2/6x6unKhlUEAGiYWiP5n+58YPsnu2373s4HEfHjBtYEAGiQWiFfPQ3ztL1sAwA0oVohH5M8nug5AKDJ1Fq75um2L1Zl1L7zsbLn3fV2ki1X3C9pY0Scvk+VAgCmrFbIXyXpoAkeS9LVU+jnQkkbJE16IhcA0Hh7DfmI+Nj+dmC7R9Jpkj4p6eIauwMAGqjmdfK2X23757YftT1k+2e2XzOFPj4naYWk8kQbbS+33W+7f2io3lUUAAD1qHWd/L9K+rikj6qyPs3hkj4m6aO2l9c6uO3TJT0SEWsm2ydbAK03Inq7u+ue5gcA1KHWnPxFqiwz/Leqtltsv1rSLyStrvH6JZKWZiP/2ZIOtv3NiHjTPlcMAKhbzevkdwt4SVJEbKrn4BHx/ojoiYiFks6WdAsBDwDTp1bIP2b72N0bs7amuZk3AGBitaZrLpZ0k+2vSVqjygegTpD0FklTGpFHxE9VtUwCACB/tUL+HElvkPRKVYK9JGm9pBMj4q851wYA2E+1Qv6Pki6TdIikb0u6NiLW5l4VAKAhat3+7/MR8WJJJ0n6m6Sv2d5g+8O2nzMtFQIA9lldNw2JiPsj4tKIOE6V6ZvXq7JMAQCgidUV8rbbbb/W9jWS/kvSHyQty7UyAMB+2+ucvO1/VuXk62mS7lBlXn55RDw+DbUBAPZTrROvH5D0LUnvnehDUQCA5lZrFcqXT1chAIDGq2tOHgDQmgh5AEgYIQ8ACSPkASBhhDwAJIyQB4CEEfIAkDBCHgASRsgDQMIIeQBIGCEPAAkj5AEgYYQ8ACSMkAeAhBHyAJAwQh4AEkbIA0DCCHkASBghDwAJI+QBIGGEPAAkjJAHgIQR8gCQMEIeABKWTMhvGh7Vuge3aNPwaNGlAEDTaMvz4LafKekbkp4hqSxpdUR8vtH93Lh2o1b2Dai9VNJYuaxVyxZp6eIFje4GAFpO3iP5HZIuiYijJZ0o6XzbxzSyg03Do1rZN6BtY2VtHd2hbWNlregbYEQPAMo55CPi4Yi4K3u8VdIGSQ0dYg9uHlF7afy30V4qaXDzSCO7AYCWNG1z8rYXSjpO0u27tS+33W+7f2hoaMrH7enq1Fi5PK5trFxWT1fnvhcLAImYlpC3PVdSn6T3RMRj1dsiYnVE9EZEb3d395SPPW9uh1YtW6TZ7SUd1NGm2e0lrVq2SPPmdjSoegBoXbmeeJUk2+2qBPw1EXFDHn0sXbxAS46Yr8HNI+rp6iTgASCT99U1lvQVSRsi4rN59jVvbgfhDgC7yXu6ZomkN0s62fba7Os1OfcJAMjkOpKPiF9Icp59AAAml8wnXgEAeyLkASBhhDwAJIyQB4CEEfIAkDBCHgASRsgDQMIIeQBIGCEPAAkj5AEgYYQ8ACSMkAeAhCUT8puGR7XuwS3c2xUAquR+05DpcOPajVrZN6D2Uklj5bJWLVukpYsbeitZAGhJLT+S3zQ8qpV9A9o2VtbW0R3aNlbWir4BRvQAoARCfnDziNpL47+N9lJJg5tHCqoIAJpHy4d8T1enRsZ2jGsbGduhnq7OgioCgObR8iEvSZVbyU7+HABmqpYP+cHNI3t8E6WsHQBmupYP+TkHzNLoEzGubfSJ0JwDZhVUEQA0j5YP+ce3P6G23b6LtlKlHQBmupYP+TkHzNKO8vi2HWUxkgcAJRDyD/1925TaAWAmafmQl2KK7QAwc7R8yD/3kKeofdb4SybbZ1nPPeQpBVUEAM2j5UN+3twOXX7WsepoKz35dflZx2re3I6iSwOAwrV8yEuViZmIshTZvwAASQmE/KbhUV3y3bXa/oQ0+kRZ25+QLv7uWhYoAwAlEPLrH3pswkso1z/0WDEFAUATafmQf2xk+5TaAWAmafmQlyZbjIxFygAggZDnOnkAmEwCIc9IHgAmk3vI236V7d/b/pPt9zX6+H9+ZOuU2gGg2WwaHtW6B7fkclVgriFve5akKyW9WtIxks6xfUwj+/jP2+6bUjsANJMb127Ukktv0Zuuvl1LLr1FN63d2NDj5z2Sf6GkP0XEXyJiu6RvSzqjkR08+n87ptQOAM1i0/CoVvYNaNtYWVtHd2jbWFkr+gYaOqLPO+QXSHqw6vlg1vYk28tt99vuHxoayrkcAGgeg5tH1F4aH8PtpVJD72yXd8hPdPZz3GUvEbE6Inojore7uzvncgCgefR0dWqsPP7TnGPlsnq6OhvWR94hPyjpmVXPeyQ91MgO7vv0aVNqB4BmMW9uh1YtW6TZ7SUd1NGm2e0lrVq2qKELLDoiv+vJbbdJ+oOkUyRtlHSnpDdExPqJ9u/t7Y3+/v596mvh+3745GMCHkAr2TQ8qsHNI+rp6tyngLe9JiJ6J9rWtt/V7UVE7LD9Lkn/LWmWpK9OFvD7i2AH0Krmze3IbXn0XENekiLiR5J+lHc/AIA9JfCJVwDAZAh5AEgYIQ8ACSPkASBhuV5COVW2hyTdvx+HmC/p0QaV0+p4L3bhvdiF92KXlN6LQyNiwk+TNlXI7y/b/ZNdKzrT8F7swnuxC+/FLjPlvWC6BgASRsgDQMJSC/nVRRfQRHgvduG92IX3YpcZ8V4kNScPABgvtZE8AKAKIQ8ACUsi5PO+WXirsP1M2/9re4Pt9bYvLLqmotmeZfs3tn9QdC1Fsv1U29fb/l328/Hiomsqiu2Lst+Pe2xfa3t20TXlqeVDfjpuFt5Cdki6JCKOlnSipPNn8Hux04WSNhRdRBP4vKSbI+IoScdqhr4nthdIerek3oh4nipLoJ9dbFX5avmQ1zTcLLxVRMTDEXFX9nirKr/IC/b+qnTZ7pF0mqSri66lSLYPlnSSpK9IUkRsj4gtxVZVqDZJndlNjQ5Ug+9W12xSCPmaNwufiWwvlHScpNuLraRQn5O0QlK51o6JO0zSkKSvZVNXV9ueU3RRRYiIjZIuk/SApIcl/T0iflxsVflKIeRr3ix8prE9V1KfpPdExGNF11ME26dLeiQi1hRdSxNok3S8pC9FxHGSHpc0I89d2e5S5S/9Z0k6RNIc228qtqp8pRDyud8svJXYblcl4K+JiBuKrqdASyQttX2fKlN4J9v+ZrElFWZQ0mBE7Pyr7npVQn8mOlXSvRExFBFjkm6Q9JKCa8pVCiF/p6Rn236W7QNUOYlyU8E1FcK2VZl33RARny26niJFxPsjoiciFqryM3FLRCQ9YptMRPxV0oO2j8yaTpH02wJLKtIDkk60fWD2+3KKEj8Jnfs9XvM2nTcLbwFLJL1Z0t2212ZtH8jus4uZ7QJJ12QDob9IelvB9RQiIm63fb2ku1S5Gu03Snx5A5Y1AICEpTBdAwCYBCEPAAkj5AEgYYQ8ACSMkAeAnNn+qu1HbN9Tx74n2b7L9g7bZ+627WbbW6ay4B4hDwD5+7qkV9W57wOS3irpWxNs+4wql0nXjZBHy7P9D7a/ZfsvttfYvs3267NtL7V9R7bE7u9sL6963Udtb7S9Nlt2dukkx39Fdkxnz2dlr9mvT0raPs/23dmxfsGKoemKiJ9L+lt1m+3Ds5H5Gtu32j4q2/e+iBjQBGsuRcRPJG2dSt+EPFpaFrzfk/TziDgsIl6gyidce2w/Q5XR0HnZErsvlfQO26dVHeKKiFgs6SxJX7W9x+9EtoDV/ZLOzZoukHRnRPxqP+puk/StiHh+1v8qSTP6U8oz0GpJF2Q/s++V9MU8Omn5T7xixjtZ0vaI+I+dDRFxv6Qv2P64pK9XLb/8qO0Vkj4q6YfVB4mIDbZ3SJov6ZEJ+rlI0i9s3ybpXZJeaPsVkj4mqUPSnyW9LSKGbX9Y0msldUr6laR3RETY/mn2fImkmyLi8qrjz9EMX1hvJskWEXyJpOuyPxClys9RwzGSR6t7riofUZ9s2+6rUPZn7ePYfpEqfx4PTXSgiHhYlaWLb5P0CVV+dz4k6dSIOD477sXZ7v8eESdkN6XolHR61aGeGhH/tDPgbZ9v+8+qjOTfXeN7RTpKkrZExOKqr6Pz6ghIhu0rba+zfacqy1BPNDqubrsoW+fnMkn/Entf5+NKSbMi4uuq3HnrGEm/zF7/FkmHZvu93Pbttu9W5S+N6v9UvjOukIgrI+JwSStV+U8DM0C2BPi9ts+SKtOOto/Noy9CHq1uvaqWzY2I81VZWbA729a72/4v0PgVGK/IRlEvi4hb99ZRRJS16z8IS/qfqlHYMRFxbna/0C9KOjMini/pKknV9xB9fJLDf1vS6/bWP1qX7WtV+SvwSNuDts+V9EZJ59pep8rP6hnZvifYHlTlPNGXba+vOs6tkq6TdEp2nFfW6ps5ebS6WyR9yvY7I+JLWduB2b9XSrrd9g0Rsdb2PEmXSvq3BvT7a0lX2j4iIv5k+0BV7mWwcz7/0Wze9UxV1m/fg+1nR8Qfs6enSfrjRPuh9UXEOZNs2uOyyoi4U5WfpYmO87Kp9k3Io6VlJzRfJ+mK7KTqkCqj5ZUR8XB215+rbB+kyuj7cxHx/Qb0O2T7rZKutb3zhNmHIuIPtq+SdLek+1S538Fk3mX7VEljkjarMuUDNBRLDQNAwpiTB4CEMV0DVLH9QVVOeFW7LiI+WUQ9wP5iugYAEsZ0DQAkjJAHgIQR8gCQMEIeABL2/49dWbAKxrd3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.scatter('GOP_Year3','VOE_Year3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference:</b>The single point on GOP_Year3 might going to be messing up with the whole statistical analysis. Let's remove them from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find out the data which is an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers for GOP_Year3 outlier: 1\n",
      "Number of outliers for VOE_Year3 outlier: 9\n"
     ]
    }
   ],
   "source": [
    "def check_outlier(value,mean,sd):\n",
    "    z = abs((value-mean)/sd)\n",
    "    return z > 3.5\n",
    "mean = df.GOP_Year3.mean()\n",
    "sd = df.GOP_Year3.std()\n",
    "df['GOP_Year3_is_outlier'] = df.GOP_Year3.apply(lambda row: check_outlier(row,mean,sd))\n",
    "\n",
    "mean = df.VOE_Year3.mean()\n",
    "sd = df.VOE_Year3.std()\n",
    "df['VOE_Year3_is_outlier'] = df.VOE_Year3.apply(lambda row: check_outlier(row,mean,sd))\n",
    "print('Number of outliers for GOP_Year3 outlier: {}'.format(len(df[df.GOP_Year3_is_outlier])))\n",
    "print('Number of outliers for VOE_Year3 outlier: {}'.format(len(df[df.VOE_Year3_is_outlier])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9.999000e+03\n",
       "mean     1.780014e+06\n",
       "std      1.715855e+07\n",
       "min      0.000000e+00\n",
       "25%      4.662500e+04\n",
       "50%      1.000000e+05\n",
       "75%      3.800000e+05\n",
       "max      1.193961e+09\n",
       "Name: GOP_Year3, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_outliers = df[df.GOP_Year3_is_outlier==False]\n",
    "df_without_outliers.GOP_Year3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference:</b> As expected from the graph above 1 data point is an outlier in GOP_Year3. We shall elliminate that. But there are 9 data points as outliers for VOE_Year3. Losing out 9 more data can be problematic. We shall keep them and move forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1. The 95 percent confidence interval for the “Gross output – Year 3 (Rs)\n",
    "To perform this we will construct a 2 sided 95% confidence interval by t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Gross output – Year 3 of population is expected to lie between Rs. 1443654.578 and Rs. 2116372.612\n"
     ]
    }
   ],
   "source": [
    "confidence_interval = 0.95\n",
    "sample_std_dev = df_without_outliers.GOP_Year3.std()\n",
    "number_of_samples = len(df_without_outliers.GOP_Year3)\n",
    "sample_mean = df_without_outliers.GOP_Year3.mean()\n",
    "lower, higher = t_ci(confidence_interval,sample_std_dev,number_of_samples,sample_mean)\n",
    "print('Mean of Gross output – Year 3 of population is expected to lie between Rs. {} and Rs. {}'.format(lower,higher))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='metrics_definition'></a>Question 2: Defining metrics for performance of the units\n",
    "We define the performance of the units as follows:<br>\n",
    "1. <b>op_per_asset = GOP_Year3/MKT_VAL_FA.</b><br>\n",
    "This metric is useful in determining how the units are performing on the basis of utilization of the fixed assets. As a basic understanding more the MKT_VAL_FA more should be GOP_Year3. If the ratio is low for any unit it means there might be a problem of under utilization of resources happening in that given unit. Also if the ratio is too high denotes the units are working with highly deprecated assets which can be a great risk sooner or later.\n",
    "\n",
    "\n",
    "2. <b>op_per_employee: GOP_Year3/EMP_TOTAL</b><br>\n",
    "In these world of automation initiatives to increase productivitiy of business this metric is very useful. If the ratio is too low it means those units might potentially show redundancies in job roles. Employees of those units might be available to take up newer challenging roles which in turn will be increasing the business. Units showing too high value might be facing employee shortage problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of the two metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_per_asset</th>\n",
       "      <th>op_per_employee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9997.000000</td>\n",
       "      <td>9.999000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>inf</td>\n",
       "      <td>1.479189e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.660946e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.760000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.421429e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.790667</td>\n",
       "      <td>7.575000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>inf</td>\n",
       "      <td>7.595800e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       op_per_asset  op_per_employee\n",
       "count   9997.000000     9.999000e+03\n",
       "mean            inf     1.479189e+05\n",
       "std             NaN     9.660946e+05\n",
       "min        0.000000     0.000000e+00\n",
       "25%        0.450000     1.760000e+04\n",
       "50%        0.900000     3.421429e+04\n",
       "75%        1.790667     7.575000e+04\n",
       "max             inf     7.595800e+07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_without_outliers['op_per_asset'] = df_without_outliers['GOP_Year3']/df_without_outliers['MKT_VAL_FA']\n",
    "df_without_outliers['op_per_employee'] = df_without_outliers['GOP_Year3']/df_without_outliers['EMP_TOTAL']\n",
    "print('Description of the two metrics')\n",
    "display(df_without_outliers[['op_per_asset','op_per_employee']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference:</b>It seems there are some rows in the data where the MKT_VAL_FA = 0 due to which we are getting inf values. This seems to be some sort of a data collection issue. To avoid this we filter the data to remove the inf values. Also there seems to be some missing values too. <a id='outlier1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_per_asset</th>\n",
       "      <th>op_per_employee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9952.000000</td>\n",
       "      <td>9.954000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.395023</td>\n",
       "      <td>1.476742e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.030814</td>\n",
       "      <td>9.679534e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.750075e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.891083</td>\n",
       "      <td>3.406559e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.762542</td>\n",
       "      <td>7.526600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>601.500000</td>\n",
       "      <td>7.595800e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       op_per_asset  op_per_employee\n",
       "count   9952.000000     9.954000e+03\n",
       "mean       2.395023     1.476742e+05\n",
       "std       12.030814     9.679534e+05\n",
       "min        0.000000     0.000000e+00\n",
       "25%        0.450000     1.750075e+04\n",
       "50%        0.891083     3.406559e+04\n",
       "75%        1.762542     7.526600e+04\n",
       "max      601.500000     7.595800e+07"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "filtered_df = df_without_outliers[~df_without_outliers.op_per_asset.isna()]\n",
    "filtered_df = df_without_outliers[df_without_outliers.op_per_asset != math.inf]\n",
    "filtered_df[['op_per_asset','op_per_employee']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference:</b> This resulted in losing out around 40 data points from our sample. There can be a separate analysis how those 40 data points had MKT_VAL_FA = 0. But this is out of scope for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: 99% confidence interval for the population mean of the above metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 99% confidence interval for op_per_asset:\n",
    "Since we have described that both low op_per_asset and high op_per_asset is a problem [here](#metrics_definition), we will define two sided confidence interval for the given metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = 0.99\n",
    "sample_std_dev = filtered_df.op_per_asset.std()\n",
    "number_of_samples = len(filtered_df.op_per_asset)\n",
    "sample_mean = filtered_df.op_per_asset.mean()\n",
    "two_sided = True\n",
    "lower, higher = t_ci(confidence_interval,\n",
    "                     sample_std_dev,\n",
    "                     number_of_samples,\n",
    "                     sample_mean,\n",
    "                     two_sided\n",
    "                    )\n",
    "print('Mean of Output Per Asset as of Year 3 of population is expected to lie between {} and {}'.format(lower,higher))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 99% confidence interval for op_per_employee:\n",
    "Since we have described that both low op_per_employee and high op_per_asset is a problem [here](#metrics_definition), we will define two sided confidence interval for the given metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = 0.99\n",
    "sample_std_dev = filtered_df.op_per_employee.std()\n",
    "number_of_samples = len(filtered_df.op_per_employee)\n",
    "sample_mean = filtered_df.op_per_employee.mean()\n",
    "two_sided = True\n",
    "lower, higher = t_ci(confidence_interval,\n",
    "                     sample_std_dev,\n",
    "                     number_of_samples,\n",
    "                     sample_mean,\n",
    "                     two_sided\n",
    "                    )\n",
    "print('Mean of Gross Output Per Employee as of Year 3 of population is expected to lie between Rs.{} and Rs.{}'.format(lower,higher))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Probability that a firm selected at random is a SSSBE unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only SSSBE units\n",
    "p = len(filtered_df[filtered_df.UNIT_TYPE==2])/len(filtered_df)\n",
    "print(f'Probability = {round(p,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Probability that a firm selected at random is GOOD in performance\n",
    "We calculate this by checking if the values of the column op_per_asset > mean of the column op_per_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_op_per_asset = filtered_df.op_per_asset.mean()\n",
    "filtered_df['good_in_performance'] = filtered_df.op_per_asset.apply(lambda row: row > mean_op_per_asset)\n",
    "p = len(filtered_df[filtered_df.good_in_performance==True])/len(filtered_df)\n",
    "print(f'Probability = {round(p,10)}')\n",
    "print('Number of units performing good = {}'.format(len(filtered_df[filtered_df.good_in_performance==True])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Probability that a firm selected is a SSSBE Unit and ALSO GOOD in performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sssbe_good_performance = len(filtered_df[(filtered_df.UNIT_TYPE==2) \\\n",
    "                                            &(filtered_df.good_in_performance==True) \\\n",
    "                                       ])\n",
    "print('Probability that firm is SSSBE Unit and also a good performer = {0:.3f}'.format(n_sssbe_good_performance/len(filtered_df)))\n",
    "p_good_given_sssbe = n_sssbe_good_performance/len(filtered_df[(filtered_df.UNIT_TYPE==2)])\n",
    "print('Conditional probability that a firm is Good given that its SSSBE:{}'.format(p_good_given_sssbe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Conclusion about performance of SSSBE units\n",
    "From calculation in 4c. we can see that only a mere 3.5% of our sample data comprise of performances from SSSBE units which are performing good. But to conclude whether SSSBE units performance are good or bad in compared to SSI we have to do a comparative study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ssi_good_performance = len(filtered_df[(filtered_df.UNIT_TYPE==1) \\\n",
    "                                            &(filtered_df.good_in_performance==True) \\\n",
    "                                       ])\n",
    "print('Probability that firm is SSI Unit and also a good performer = {0:.3f}'.format(n_ssi_good_performance/len(filtered_df)))\n",
    "p_good_given_ssi = n_ssi_good_performance/len(filtered_df[(filtered_df.UNIT_TYPE==1)])\n",
    "print('Conditional probability that a firm is Good given that its SSI:{}'.format(p_good_given_ssi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference: </b>From the above calculations it is clear that:\n",
    "1. A majority of good performer is SSI units and not SSSBE units in our sample.\n",
    "1. If we see the conditional probability to understand if given that a firm is an SSSBE unit what is the probability that it will perform good < if given that a firm is SSI Unit what is the probability of being good performer.\n",
    "\n",
    "Based on these above caclculations it is evident that performance of SSSBE unit is not good as compared to SSI Units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Null Hypothesis test\n",
    "Null hypothesis H<sub>0</sub>: Population mean of VOE_Year3 = 87,300 <br>\n",
    "Alternate Hypothesis H<sub>1</sub>: Population mean of VOE_Year3 ≠ 87,300 <br>\n",
    "We will setup a one sided confidence interval of 0.95 <br>\n",
    "Since population standard deviation is not given to us we will use sample standard deviation and use t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outliers.VOE_Year3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = 0.95\n",
    "sample_std_dev = df_without_outliers.VOE_Year3.std()\n",
    "number_of_samples = len(df_without_outliers.VOE_Year3)\n",
    "mean = 87300\n",
    "two_sided = False\n",
    "lower, higher = t_ci(confidence_interval,sample_std_dev,number_of_samples,mean,two_sided)\n",
    "sample_mean = df_without_outliers.VOE_Year3.mean()\n",
    "print('Sample Mean for Value of Exports for Year 3 is expected to lie between Rs. {} and Rs. {}'.format(lower,higher))\n",
    "print(f'Does sample mean falls within above range? Ans: {lower<=sample_mean<=higher} and the value {sample_mean}')\n",
    "print(f'The t value for sample mean:{t.cdf(sample_mean,df=number_of_samples-1,loc=mean,scale=sample_std_dev/number_of_samples**0.5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference:</b> It is evident that from the one sided t-test though the sample mean lies between the given ranges the P value is << 0.05. Hence we can surely reject the Null hypothesis that the population mean of VOE_Year3 is 87300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Special incentives for SSSBE or SSI or both\n",
    "<b>Explanation:</b> Below we will define the success criteria as follows:\n",
    "1. If unit is an SSSBE Unit its a success. We calculate the population proportion of its success rate.\n",
    "1. If unit is an SSI Unit its a success. We calculate the population proportion of its success rate.\n",
    "\n",
    "For the unit to get incentives the population proportion of it should be < 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = 0.99\n",
    "sssbe_count = len(filtered_df[filtered_df.UNIT_TYPE==2])\n",
    "total_count = len(filtered_df)\n",
    "\n",
    "\n",
    "sssbe_pop_prop = proportion_confint(count=sssbe_count,    # Number of \"successes\"\n",
    "                                   nobs=total_count,    # Number of trials\n",
    "                                   alpha=(1 - confidence_interval))\n",
    "print('Population proportion of SSSBE units is expected to lie within {} by confidence interval of {}'.format(sssbe_pop_prop, confidence_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = 0.99\n",
    "sssbe_count = len(filtered_df[filtered_df.UNIT_TYPE==1])\n",
    "total_count = len(filtered_df)\n",
    "\n",
    "sssbe_pop_prop = proportion_confint(count=sssbe_count,    # Number of \"successes\"\n",
    "                                   nobs=total_count,    # Number of trials\n",
    "                                   alpha=(1 - confidence_interval))\n",
    "print('Population proportion of SSI units is expected to lie within {} by confidence interval of {}'.format(sssbe_pop_prop, confidence_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference:</b> Since SSSBE Unit's population proportion is expected to be lying below 25% we would recommend these special incentives for SSSBE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Contention that a larger proportion of SSSBEs are managed by men as compared to women\n",
    "<b>Explanation:</b> For this we will estimate population proportion of SSSBE Units managed by Male. The column MAN_BY will be beneficial for this case.\n",
    "1. We define success if a unit is managed by man.\n",
    "1. We estimate the population proportion of SSSBE units to be managed by men from our sample by a set confidence interval.\n",
    "1. If the estimated population proportion > 0.5 this contention will hold true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out only SSSBE Units\n",
    "sssbe_df = df[df.UNIT_TYPE == 2]\n",
    "sssbe_df.MAN_BY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = 0.99\n",
    "no_of_sssbe_units_managed_by_men = len(sssbe_df[sssbe_df.MAN_BY == 1])\n",
    "number_of_sssbe_units = len(sssbe_df)\n",
    "male_employee_pop_prop = proportion_confint(count=no_of_sssbe_units_managed_by_men,    # Number of \"successes\"\n",
    "                                           nobs=number_of_sssbe_units,    # Number of trials\n",
    "                                           alpha=(1 - confidence_interval))\n",
    "print('Population proportion of SSSBE units being managed by men is expected to lie within {} by confidence interval of {}'.format(sssbe_pop_prop, confidence_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference:</b> Thus we are 99% confident that the population proportion of SSSBE Units being managed by men lies much above 50%. Hence we are accepting the above contention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Distribution of defined metrics <a id='normal_check'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[['op_per_asset','op_per_employee']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['op_per_asset'].plot.hist(bins=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['op_per_employee'].plot.hist(bins=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference:</b> The distributions of the metrics 'op_per_asset' and 'op_per_employee' are right skewed in nature. We can find the evidence from the above histograms and also the .describe() method [here](#normal_check) where it is seen that median << mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
